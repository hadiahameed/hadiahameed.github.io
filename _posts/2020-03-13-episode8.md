---
layout: post
title: "Episode 8: Fundamentals of Machine Learning Theory"
description: Notes from Tom M. Mitchell's book (Part I)
tags: [machinelearning, theory, datascience]
date: 2020-03-13
---

These days I am reading the book <a href="http://www.cs.cmu.edu/~tom/mlbook.html">"Machine Learning"</a> by Tom M. Mitchell and I will be documenting some important concepts from its chapters in a series of blog posts.

## [Background/Important Terminology]: 
1. Machine learning is about getting good at some task T with experience E and measuring the performance by some measure P. e.g. a machine learning to play Ludo. The task T is to win the game. Experience E is the games played by the machine. Performance P is how many games it has won so far.  
2. **Instances** refer to examples in the training data.  
For example, in the following table, Outlook, Temperature, Humidity, Wind are **features** and Play Tennis is the output or **target class**. A machine is given these features and asked to predict the output class. An instance refers to a row of the table. (\<Sunny,Hot,High,Weak\>,No) means that for features \<Sunny,Hot,High,Weak\>, the target class is "No"
<figure>
    <img src="http://3.bp.blogspot.com/-hVprB_8Fs24/UJ0J6blIV4I/AAAAAAAAALg/ihNqb4yJ1Lo/s640/decision-tree-table-tennis.png" width="55%" height="55%">
    <figcaption>Source: <a href="http://geniferology.blogspot.com/2012/11/about-logic-and-how-to-do-it-fast.html">About logic, and how to do it fast, Geniferology</a></figcaption>
</figure>

3. Target Concept and Hypothesis: **"Target concept"** refers to the true function that maps all the features to it's correct output. We may never find the this function because we don't have access to all the possible examples for a concept in the world e.g. we don't have data for all the games of Ludo ever played in time and space. But what we can do is try to guess this target concept, which is called **"Hypothesis"**. Hypothesis can be equal to target concept if our learning was perfect but often hypothesis is just the best approximation of the target concept.]  


## Concepts:  
+ <span style="color:blue">What is the difference between direct and indirect training examples?</span>  
For example, in a game of Ludo, the model can be given all the different ways in which the pieces can be moved across the board (all the legal state transitions), and the set of correct moves that will result in winning/losing the game. These are **direct training examples**.  
**Indirect training examples** include all the moves made in the past and their corresponding outcome (win/loss). The model has to indirectly infer patterns from these examples. This is done by “credit assignment” which means the model has to learn the weights/credits for each move in order maximize the end reward.  
Direct training feedback is usually easier than learning from indirect feedback. 

+ <span style="color:blue">What is Least Mean Square (LMS) training rule?</span>  
It is a weight updating technique in which the weights are adjusted by a small amount in the direction that reduces the training error. It is used in perceptron training, stochastic gradient descent etc.

<figure>
    <img src="https://image.slidesharecdn.com/neuralnetworkformachinelearning-140705101800-phpapp01/95/neural-network-for-machine-learning-33-638.jpg?cb=1404555633" width="75%" height="75%">
    <figcaption>Source: <a href="https://www.slideshare.net/11Ujjawal/neural-network-for-machine-learning">Neural network for machine learning by Ujjawal</a></figcaption>
</figure> 

+ <span style="color:blue">What is concept learning?</span>  
It means to “infer a boolean-valued function from training examples of its input and output … It can be considered as a task of searching through a large predefined space of potential hypotheses.” It's kind of like classification. 
 
+ <span style="color:blue">What is inductive learning?</span>  
Inductive learning algorithms guarantee that the target concept will fit the training data perfectly. The core assumption in inductive learning is that the unseen data will follow the distribution of the training data so our learned hypothesis will fit the unseen data too. Formally, the inductive learning hypothesis says:  
1. Any hypothesis found to approximate the target concept well over a sufficiently large set of training examples will also approximate the target concept well over other unobserved examples.  
2. Inductive learning makes certain assumptions called **inductive bias** that help it classify unseen instances. For example, an inductive learner might assume that the output class can only be expressed as a conjunction (AND gate) of input variables:  
(e.g. If Temperature = High AND Wind = Weak AND Humidity = Low then class is positive).  
The leaner is biased in that it does not allow any disjunctions (e.g. Temperature = High OR Low) here.  
3. Usually inductive learners are compared based on the strength or weakness of the inductive biases they make.  
Decision Trees are an example of inductive learning, which allow disjunction of conjunctions.  
(e.g. If (Temperature = Low AND Wind = Weak) OR (Humidity = High AND Wind = Weak), Play_Tennis = Yes))

+ <span style="color:blue">What is meant by syntactically and semantically distinct hypotheses?</span>  
Consider a feature space X = [Temperature, Wind, Humidity]. Temperature can take 3 distinct values, whereas Wind and Humidity each take 2 distinct values. Then there can be **3 * 2 * 2 = 12** distinct instances with all the possible combinations of the three features.  
A hypothesis means a function or mapping that we try to learn to predict whether one should play outside or not, based on the values of X.  For example:  
(\<High,Weak,Low\>,1) means when the temperature is high, wind is weak and humidity is low, one can play outside (Target class = 1).  
Similarly (<?,Strong,?>, 0) implies that I don’t care what the temperature or humidity is, as long as there is strong wind, I won’t play outside (target class = 0). “?” here is called a wild card.  
Moreover, (**<&Phi;, &Phi;, &Phi;,1>**) means I have no information about the features (empty instances) so I will play outside.   
This means that each feature can take the following values  
Temperature (3 + 2 = 5): High, Low, Medium, ?, &Phi;  
Wind (2 + 2 = 4): Strong, Weak, ?, &Phi;  
Humidity ( 2 + 2 = 4): Low, High, ?, &Phi;  
So, the number of **syntactically distinct hypotheses** is **5 * 4 * 4 = 80**  
But if there is even a single &Phi; in the input vector, it means that values for all the other features are also unknown. In other words, if we do not know what temperature it is, we also do not know about humidity and wind. There is only a single instance with &Phi;. So, the number of **semantically distinct hypotheses** is **(4 * 3 * 3) + 1 = 37**  
This is the entire hypotheses space that we will need to search in order to learn a concept and use machine learning to decide whether we should play outside or not.   

+ <span style="color:blue">How do you interpret the following expressions:</span>

1. **C : X &rarr; {0,1}**  
There is a target concept **C** that we aim to learn. **X** is the set of instances over which **C** is defined. The target concept **C** maps the set of instances **X** to a set of boolean values 0 and 1.  
Example: Predicting whether to play outside or not based a set of features X = Temperature, Wind, Humidity.
In this case, C(X) = 1 means play outside. C(X) = 0 means don't play outside. 
2. **(&forall; x &epsilon; X)[(h2 (x) = 1) &rarr; (h1(x) = 1)]**
This is called **more_general_than_or_equal_to rule**. It means for any instance x in X, if it satisfies hypothesis h2, it also satisfies hypothesis h1, which implies that *h1 is more general than h2*. For example:  
H1 = <High, ? ,?> Temperature is high and I don’t care about other variables.  
H2 = <High,Weak,?> Temperature is high, wind is weak and I don’t care about humidity. 
H1 is more general than H2 as it will classify all instances with high wind as class = 1, where h2 is more specific and requires wind to be weak as well as temperature to be high for the output class to be 1.  
3. <img src="{{site.baseurl}}/assets/induction" width="30%" height="30%">
D is the training data x is a new instance from the test set. L is a learner. The expression means that L inductively infers from the training data and test instance that the class of x is L(x,D) = 1 (positive).

+ <span style="color:blue">What is a fast way to check if an element is present in a list?</span>
Common way to look for an element inside a list is: **if x in myList**  
This can be time-consuming if the list is very large. A shortcut is: **if x in set(myList)** because set() extracts all the unique elements in myList and shortens it. Of course, this is only useful when the list has many duplicates.  

+ <span style="color:blue">A good resource for learning basic concepts of Algorithms?</span>
<a href="http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-046JFall-2005/CourseHome/">"Erik Demaine, Charles Leiserson Introduction to Algorithms"</a>

<figure>
    <img src="https://i.stack.imgur.com/SZ7jy.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://medium.com/@shawnren527/learn-about-python-3-data-types-numbers-and-strings-76c75a917c9b">Difference between Big-O and Little-O Notation - Stack Overflow</a></figcaption>
</figure> 

+ <span style="color:blue">What is lambda notation in Python?</span>  
If you want to write a function that has no local variables except the ones that are given as an input, you can use lambda notation.
<img src="{{site.baseurl}}/assets/python.png" width="20%" height="20%">  



## Thought of the Week:  
A couple of days ago I came across an article shared by Yann LeCun (the father of Convolutional Neural Networks (CNN) and also a professor at NYU), titled <a href="https://towardsdatascience.com/the-most-important-supreme-court-decision-for-data-science-and-machine-learning-44cfc1c1bcaf">"The Most Important Court Decision For Data Science and Machine Learning"</a> by Matthew Stewart [4]. This article gives a quick rundown of the famous Authors Guild vs Google case which dragged on for more than ten years, becoming the most important case study in the field of artificial intelligence and machine learning. In 2005, two famous publishers in the US sued Google for using copyrighted books for training their book search algorithms.  

Google books search algorithm is a highly sophisticated machine learning algorithm for optimizing book search for users.  
Recently, I searched for a couple of titles to understand how the algorithm actually worked. When I entered general keywords like "Lab" or "Blood", it didn't list the books based on word frequency in the existing database of books (because that would have simply given me a list of medical books), instead the algorithm also took into account the popularity of the books in other web searches (which is based on PageRank algorithm). For example, for "blood", the book "Bad Blood" by John Carreyrou was among the top results. It is said that Google has scanned more than 15 million books and put them on web [5].
 
Anyhow, the end result of the famous case between Authors Guild and Google was that the Supreme Court eventually dismissed the lawsuit and Google was officially let off the hook. But the ruling helped establish some important precedents in Artificial intelligence, such as affirming that the *"use of copyrighted material ... to train a discriminative machine-learning algorithms (such as for search purposes) is legal"* [4] But how would that fare in generative machine learning to produce deep fakes, is still an open question. 

 Until next time! 

## References:
[1] [Big Data Essentials](https://www.coursera.org/learn/big-data-essentials/home/welcome)  
[2] [What’s the difference between Scripting and Programming Languages?](https://www.geeksforgeeks.org/whats-the-difference-between-scripting-and-programming-languages/)  
[3] [A Deeper Inspection Into Compilation And Interpretation](https://medium.com/basecs/a-deeper-inspection-into-compilation-and-interpretation-d98952ebc842)  
[4] [Python Lists vs Dictionaries: The space-time tradeoff](https://www.jessicayung.com/python-lists-vs-dictionaries-the-space-time-tradeoff/)
