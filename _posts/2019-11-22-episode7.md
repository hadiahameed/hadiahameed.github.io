---
layout: post
title: "Episode 7: Demystifying the buzz words in Big Data"
description: Understanding fundamentals of distributed computing
tags: [bigdata, distributed computing, parallel computing]
date: 2019-11-22
---

This week I made the following notes while taking the <a href="https://www.coursera.org/learn/big-data-essentials/home/welcome">"Big Data Essentials: HDFS, MapReduce and Spark RDD"</a> course on Coursera [1].

## Concepts:  
+ <span style="color:blue">What is scaling up and scaling down?</span>  
Scaling up means increasing the capacity of each server (e.g. have a single 8TB machine). Scaling out means having more servers per data center (e.g. have several 1TB machines). Scaling up has low latency (less time delay between request and response) while scaling out has higher latency.  

<figure>
    <img src="https://nancyyanyu.github.io/posts/49a14c15/week_1.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://nancyyanyu.github.io/posts/49a14c15/">DFS, HDFS, Architecture, Scaling problem</a></figcaption>
</figure> 

+ <span style="color:blue">What is Hadoop File System?</span>  
In 2013, Google published a paper on "Google File System" (GFS) [2]. In their paper, they described the architecture of a scalable, distributed file system with high fault tolerance, using inexpensive commodity hardware. In 2005 Apache developed Hadoop File System (HDFS) which is an open source implementation of GFS. While GFS was originally written in C++, HDFS is written in Java. They both are designed to store petabytes of data across multiple nodes and can be used for data-intensive computing.  

<figure>
    <img src="https://hadoopabcd.files.wordpress.com/2015/01/image00.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://hadoopabcd.wordpress.com/2015/01/03/setting-up-hadoop-multi-node-cluster-on-amazon-ec2-2/">Setting up Hadoop Cluster on Amazon Cloud</a></figcaption>
</figure>  


+ <span style="color:blue">What is a cluster?</span>  
A cluster a network of computers. It is mostly composed of three parts [3]:
- Client: Applications accessing the data.
- Master Node: The root node that stores operation logs and acts as a manager in the network. The master does not store the actual file data and only the meta data (administrative information about the files, clusters etc.)
- Chunk servers: They act like slave nodes which stor data and work under the directions of the master node. Each node stores a fixed size of data, ususally not more than 64 or 128 MB.  

<figure>
    <img src="https://ucdavis-bioinformatics-training.github.io/2018-Dec-Genome-Assembly/cluster-slurm/cluster_diagram.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://ucdavis-bioinformatics-training.github.io/2018-Dec-Genome-Assembly/cluster-slurm/cluster.html">UC Davis Bioinformatics Core December 2018 Genome Assembly workshop</a></figcaption>
</figure>


+ <span style="color:blue">How are HDFS and YARN realted to each other?</span>   
<img src="{{site.baseurl}}/assets/hadoop.png" width="75%" height="55%">      

+ <span style="color:blue">In a distributed file system (DFS), you can “append” into a file, but cannot “modify” a file in the middle. Why? [1]</span> 
DFS is based on a data usage pattern called "write-once-read-many" (WORM) which suits the kind of data collection that Google does. It also simplifies its API



## Thought of the Week:  
This week I found myself in a rut when I sat down to organize my Machine Learning notes. Taking a course in Machine Learning, I have come to realize, is like going to Ikea. You like everything and you want to buy everything but you rarely need all those things at the same time. So, earlier this week, I rolled up my sleeves, picked up my data-mining shovel and decided to dig deep into the topic of bias-variance tradeoff, only to end up having a vertigo as I jumped from one concept to another, with a hundred different tabs opened up in my browser. But one good thing that came out of it was discovering a new blog on probability theory called <a href="https://www.countbayesie.com">Count Bayesie"</a> (which is already up on my favorite list of blogs), when I was trying to find out <a href="https://www.countbayesie.com/blog/2019/1/30/a-deeper-look-at-mean-squared-error">how to expand the expectation of mean squared error </a>(geeky segue alert!). Discovering a good resource in data science makes me realize how far I am from where I want to be in this field, but it is also like discovering a new trail along the way, a detour which might make this long, arduous journey plagued with frequent fits of self-scrutiny and imposter syndrome, more fun and exploratory. There is so much to learn and you get a day everyday to do it. What more could one ask for? Happy reading!  

See you next week!
 
## References:
[1] [Big Data Essentials](https://www.coursera.org/learn/big-data-essentials/home/welcome)  
[2] [Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)  
[3] [Analyzing Google File System and Hadoop Distributed File System](https://scialert.net/fulltextmobile/?doi=rjit.2016.66.74)  
[4] [A New Kullback–Leibler VAD for Speech Recognition in Noise](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1261996)  
[5] [A Kullback-Leibler Divergence Based Kernel for SVM Classification in Multimedia Applications](http://papers.nips.cc/paper/2351-a-kullback-leibler-divergence-based-kernel-for-svm-classification-in-multimedia-applications.pdf)



