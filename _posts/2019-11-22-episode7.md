---
layout: post
title: "Episode 7: Demystifying the buzz words in Big Data"
description: Understanding fundamentals of distributed computing
tags: [bigdata, distributed computing, parallel computing]
date: 2019-11-22
---

This week I made the following notes while taking the <a href="https://www.coursera.org/learn/big-data-essentials/home/welcome">"Big Data Essentials: HDFS, MapReduce and Spark RDD"</a> course on Coursera [1].

## Concepts:  
+ <span style="color:blue">What is scaling up and scaling out?</span>  
Scaling up means increasing the capacity of each server (e.g. have a single 8TB machine).  
Scaling out means having more servers per data center (e.g. have several 1TB machines).  
Scaling up has low latency (less time delay between request and response) while scaling out has higher latency.  

<figure>
    <img src="https://nancyyanyu.github.io/posts/49a14c15/week_1.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://nancyyanyu.github.io/posts/49a14c15/">DFS, HDFS, Architecture, Scaling problem</a></figcaption>
</figure> 

+ <span style="color:blue">What is Hadoop File System?</span>  

In 2003, Google published a paper on "Google File System" (GFS) [2]. In their paper, they described the architecture of a:  
1. scalable  
2. distributed file system   
3. with high fault tolerance  
4. using inexpensive commodity hardware.  

In 2005, Apache developed Hadoop File System (HDFS) which is an open source implementation of GFS.  
While GFS was originally written in C++, HDFS is written in Java. They both are designed to store petabytes of data across multiple nodes and can be used for data-intensive computing.  

<figure>
    <img src="https://hadoopabcd.files.wordpress.com/2015/01/image00.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://hadoopabcd.wordpress.com/2015/01/03/setting-up-hadoop-multi-node-cluster-on-amazon-ec2-2/">Setting up Hadoop Cluster on Amazon Cloud</a></figcaption>
</figure>  


+ <span style="color:blue">What is a cluster?</span>  

A cluster is a network of computers. It is mostly composed of three parts [3]:  

- **Client**: Applications accessing the data.
- **Master Node**: The root node that stores operation logs and acts as a manager in the network. The master does not store the actual file data and only the meta data (administrative information about the files, clusters etc.)
- **Chunk servers**: They act like slave nodes which store actual data and work under the directions of the master node. Each node stores a fixed size of data, ususally not more than 64 or 128 MB.  

<figure>
    <img src="https://ucdavis-bioinformatics-training.github.io/2018-Dec-Genome-Assembly/cluster-slurm/cluster_diagram.png" width="55%" height="55%">
    <figcaption>Source: <a href="https://ucdavis-bioinformatics-training.github.io/2018-Dec-Genome-Assembly/cluster-slurm/cluster.html">UC Davis Bioinformatics Core December 2018 Genome Assembly workshop</a></figcaption>
</figure>


+ <span style="color:blue">How are HDFS and YARN realted to each other?</span>   

<img src="{{site.baseurl}}/assets/hadoop.png" width="90%" height="75%">      

+ <span style="color:blue">In a distributed file system (DFS), you can “append” into a file, but cannot “modify” a file in the middle. Why? [1]</span>   

DFS is based on a data usage pattern called "write-once-read-many" (WORM) which suits the kind of data collection that Google does. It also simplifies its API.

## Thought of the Week:  
A couple of days ago I came across an article shared by Yann LeCun (the father of Convolutional Neural Networks (CNN) and also a professor at NYU), titled <a href="https://towardsdatascience.com/the-most-important-supreme-court-decision-for-data-science-and-machine-learning-44cfc1c1bcaf">"The Most Important Court Decision For Data Science and Machine Learning"</a> by Matthew Stewart [4]. This article gives a quick rundown of the famous Authors Guild vs Google case which dragged on for more than ten years, becoming the most important case study in the field of artificial intelligence and machine learning. In 2005, two famous publishers in the US sued Google for using copyrighted books for training their book search algorithms. Google books search algorithm is a highly sophisticated machine learning algorithm for optimizing book search for users.  

Recently I searched for a couple of titles to understand how the algorithm actually worked. When I entered general keywords like "Lab" or "Blood", it didn't list the books based on the word frequency (because that would have simply given me a list of medical books) but the algorithm took into account the popularity of the books in other web searches (which is based on PageRank algorithm). For example, for "blood", the book "Bad Blood" by John Carreyrou was among the top results. It is said that Google has scanned more than 15 million books and put them on web [5].
 
 Anyhow, the end result of the famous case between Authors Guild and Google was that the Supreme Court eventually dismissed the lawsuit and Google was officially off the hook. But the ruling helped establish some important precedents in Artificial intelligence, such as affirming that the *"use of copyrighted material ... to train a discriminative machine-learning algorithm (such as for search purposes) is legal"* [4] But how would that fare in generative machine learning to produce deep fakes, is still an open question. 

 Until next time! 

## References:
[1] [Big Data Essentials](https://www.coursera.org/learn/big-data-essentials/home/welcome)  
[2] [Google File System](https://static.googleusercontent.com/media/research.google.com/en//archive/gfs-sosp2003.pdf)  
[3] [Analyzing Google File System and Hadoop Distributed File System](https://scialert.net/fulltextmobile/?doi=rjit.2016.66.74)  
[4] [The Most Important Court Decision For Data Science and Machine Learning](https://towardsdatascience.com/the-most-important-supreme-court-decision-for-data-science-and-machine-learning-44cfc1c1bcaf)
[5] [Inside the Google Books Algorithm](https://www.theatlantic.com/technology/archive/2010/11/inside-the-google-books-algorithm/65422/)
