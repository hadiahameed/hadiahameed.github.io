---
layout: post
title: "Episode 12: Inferential Statistics and Hypothesis Testing Playbook"
description: Using a case study on comparing salaries of police and social services department in New York for 2020 and 2021.
tags: [hypothesis, statistics, data.gov, a/b testing]
date: 2024-04-25

---

This post acts as a handy cheat sheet on how to draw important inferences from a given dataset using statistics and hypothesis testing.  

## Dataset:

Citywide Payroll Data (Fiscal Year) was taken from <a href="https://catalog.data.gov/dataset/citywide-payroll-data-fiscal-year">"Data.gov"</a>. Each record represents the following statistics for every city employee: Agency, Last Name, First Name, Middle Initial, Agency Start Date, Work Location Borough, Job Title Description, Leave Status as of the close of the FY (June 30th), Base Salary, Pay Basis, Regular Hours Paid, Regular Gross Paid, Overtime Hours worked, Total Overtime Paid, and Total Other Compensation.

For the purpose of simplicity, I have extracted the base salaries for two departments i.e. Police department and Social Services for fiscal years 2020 and 2021 and have taken a subset of relevant columns. 

<img src="{{site.baseurl}}/assets/episode_12_image_1.png">  

<img src="{{site.baseurl}}/assets/episode_12_image_2.png"> 

## Concepts:  

+ <span style="color:blue">Step 1: Descriptive statistics and their interpretation.</span>       
We use the Data Analysis toolpack in Excel to quickly get descriptive stats for the two departments. Refer to sheet **"descriptive_stats"** in inferential_stats_case_study.xlsx [1].

<img src="{{site.baseurl}}/assets/episode_12_image_3.png">  

We make the following observations and come up with relevant questions related to these observation which we will later answer through various statistical tests: 

- The police department has on average higher salary than social services. 
  - *Is this difference statistically significant?*   
<br/>   
- Median salary is lower than mean salary (excluding Police 2021) This implies a right/positive skew. But the small value for "Skew" for police shows that the tails don't extend too far to the right. Kurtosis less than 3 also shows that the distribution for police's salaries is thin-tailed and outlier frequency is low. Kurtosis is > 3 for Social Services which implies a higher outlier frequency and fat-tailed distribution.    

<figure>
  <img src="{{site.baseurl}}/assets/episode_12_image_4.png">  
  <figcaption>Source: <a href="https://www.scribbr.com/statistics/kurtosis/#:~:text=Kurtosis%20is%20a%20measure%20of,(medium%20tails)%20are%20mesokurtic.">Types of kurtosis</a></figcaption>
</figure>   

- The police department's salaries vary more than the social services department as shown by the standard deviation.    

### Inferential Statistics:  

1. ### Single sample, Confidence Interval for Mean: 

+ <span style="color:blue">Step 2(a): If we know the population variance for the salary of each department, calculate the confidence interval for the mean salary of a police officer and a social worker in New York for the year 2020. Assuming that the police department's salary has a population standard deviation of $80k and social services has a population standard deviation of $60k.</span>  

Refer to sheet **"1. Known variance, CI, z-table"** in inferential_stats_case_study.xlsx [1].  

<figure>
  <img src="{{site.baseurl}}/assets/episode_12_image_5.png">  
  <figcaption>Case 1: Confidence intervals. Population known, z-table. </figcaption>
</figure>  

<p style="color:blue"> **Interpretation:** We are 95% confident that a police officer's salary will be from $67,794 to $69,256 and a social worker's salary will be from $57,861 to $60,050 in NYC in 2020.</p>

+ <span style="color:blue">Step 2(b): If we do not know the population variance for the salary of each department, calculate the confidence interval for the mean salary of a police officer and a social worker in New York for the year 2020.</span>


Refer to sheet **"2. Unkown var, CI, t-table"** in inferential_stats_case_study.xlsx [1].  

<figure>
  <img src="{{site.baseurl}}/assets/episode_12_image_6.png">  
  <figcaption>Case 2: Confidence intervals. Population uknown, t-table</a></figcaption>
</figure> 

<p style="color:blue"> **Interpretation:** We are 95% confident that a police officer's salary will be from $68,219 to $68,830 and a social worker's salary will be from $58,511 to $59,400 in NYC in 2020.</p>

+ <span style="color:blue">What are some of the ways you can convert non-gaussian features to gaussian and why is it important?</span>  
  If we are estimating the probability distribution of the negative (non-anomalous) examples using a gaussian distribution that it is important to convert all the features to a gaussian distribution. 

  If x is some feature with non-gaussian distribution then we can convert it to gaussian through the following transformations:

  $$ log(x)\\
  log(x + c\*) $$ 
  $$ \sqrt(x)\\
  x^\frac{1}{3} $$

  \* where c is some constant value selected by hit and trial. We add this to avoid log(0) case. 


   <figure>
    <img src="{{site.baseurl}}/assets/gaussian.png" width="55%" height="55%">       
    <figcaption>Source: <a href="https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning/lecture/7MOXj/choosing-what-features-to-use"> Week 1, Unsupervised Learning, Recommenders, Reinforcement Learning by Andrew Ng</a></figcaption>
   </figure> 

+ <span style="color:blue">What do we do when, after building our density estimation model we find out that the probability of an anomalous event is close to a normal event?</span>   

   In these cases, it helps to come up with a derived variables e.g. ratio of a feature that takes a very small value for anomalies and a feature that take very high value in case of anomalies. 

   <figure>
    <img src="{{site.baseurl}}/assets/problem_anomaly.png" width="55%" height="55%">       
    <figcaption>Source: <a href="https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning/lecture/7MOXj/choosing-what-features-to-use"> Week 1, Unsupervised Learning, Recommenders, Reinforcement Learning by Andrew Ng</a></figcaption>
   </figure> 

+ <span style="color:blue">What is mean normalization, why do we do it when building recommender systems? When do we do it row wise and when is it done column wise?</span>   

   Mean normalization is done by subtracting mean of every feature from each value of the feature.
   Generally, it is done to scale features. To bring all values to the same range. When it is divided by the range, the features are scaled. 

   <img src="{{site.baseurl}}/assets/mean_norm.png" width="55%" height="55%"> 

   If the denominator is standard deviation, then it the process is called standardization. The resulting distribution has 0 mean and unit variance. 

   <img src="{{site.baseurl}}/assets/mean_norm1.png" width="55%" height="55%"> 

   Optimization algorithms converge faster when the features are scaled. 

   In recommender systems, we only do mean normalization (subtract mean from each value of the rating in the per-item matrix) to fix cold-start issue. If a new user shows up in the system and we have not done mean normalization, then the algorithm will assume that the new user will give 0 rating to every movie. But after mean normalization, the algorithm will assume that the new user will rate each movie according to the average rating of that movie based on existing users. For this we do row wise mean normalization (items are in the rows and users are in the columns of the matrix).

   If a new movie shows up and no user has rated it yet, then in order to estimate it's ratings, we do column wise mean normalization. But this is not advisable.


   <figure>
    <img src="{{site.baseurl}}/assets/mean_norm2.png" width="55%" height="55%">       
    <figcaption>Source: <a href="https://www.coursera.org/learn/unsupervised-learning-recommenders-reinforcement-learning/lecture/hTjvz/mean-normalization"> Week 2, Unsupervised Learning, Recommenders, Reinforcement Learning by Andrew Ng</a></figcaption>
   </figure> 


+ <span style="color:blue">What is the difference between collaborative and content-based filtering?</span>   
  - **Collaborative Filtering**:
  Recommendations are based on ratings of other users who are considered similar to you.

  - **Content based Filtering**:
  Recommendations are based on user and item features to find a good match (with the help of dot product).
